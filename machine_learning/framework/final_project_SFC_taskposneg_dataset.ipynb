{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This lists the major steps to building and training a logistics regression model for classification__\n",
    "\n",
    "* Read in the .mat file, view the data and process the data worthy for building and training our classification model.\n",
    "* build and train our model with training datasets.\n",
    "* Test our model for accuracy using testing datasets.\n",
    "* conduct Cross validation of our model using \"leave-one-out cross-validation\" & \"k-fo;d corss-validation\" methods.\n",
    "* conduct Feature importance using both \"recursive feature elimination\" & \"permutation testing\".\n",
    "\n",
    "\n",
    " __Each step is repeated for the number of classifier models required for classifying the datasets__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Read the .mat file, view the data and process the datasets for classification__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'feature_IDs_taskposneg', 'feature_IDs_taskposneg_char', 'info_features_alldays', 'sfc_taskposneg_ComBat_day1', 'sfc_taskposneg_ComBat_day2', 'sfc_taskposneg_ComBat_day3'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the .mat file using laodmat module from scipy.io\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "input_data = loadmat('SFC_features_alldays_taskposneg.mat')\n",
    "\n",
    "#check the labels of the features of the imported dataset\n",
    "input_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sfc features = Nx36, where N are the features and 36 are the subjects\\nfeature_IDs provides the connection coordinates in the pp272 space (within the given networks) corresponding to these N features\\nComBat = site harmonization performed using the ComBat technique\\n']\n"
     ]
    }
   ],
   "source": [
    "#********************************************************************************************************************#\n",
    "# the main features required for generating our training and tresting datasets are:\n",
    "#'feature_IDs_attention';          // required for features importance\n",
    "#'feature_IDs_attention_char';     // data type of features _IDs\n",
    "#'info_features_alldays';          // metadata about the size of datasets \n",
    "#'sfc_attention_ComBat_day1';       // day1 data\n",
    "#'sfc_attention_ComBat_day2';       // day2 data\n",
    "#'sfc_attention_ComBat_day3'        // day 3 data\n",
    "#******************************************************************************************************************#\n",
    "\n",
    "# we write the features for use into variables for further data cleaning\n",
    "\n",
    "feature_ids = input_data['feature_IDs_taskposneg']\n",
    "feature_ids_char = input_data['feature_IDs_taskposneg_char']\n",
    "features_info = input_data['info_features_alldays']\n",
    "day1_data = input_data['sfc_taskposneg_ComBat_day1']\n",
    "day2_data = input_data['sfc_taskposneg_ComBat_day2']\n",
    "day3_data = input_data['sfc_taskposneg_ComBat_day3']\n",
    "\n",
    "#we can view the features information for all days\n",
    "print(features_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_ids size (4503, 2)\n",
      "feature_ids_char size (4503, 1)\n",
      "day1_data size (4503, 36)\n",
      "day2_data size (4503, 36)\n",
      "day3_data size (4503, 36)\n"
     ]
    }
   ],
   "source": [
    "# N x 36 is the size of the dataset for each day, to view the actual size of N, we use panda and numpy libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "feature_ids = input_data['feature_IDs_taskposneg']\n",
    "f_ids = pd.DataFrame(feature_ids)\n",
    "feature_ids = f_ids.to_numpy()\n",
    "print(\"feature_ids size\",feature_ids.shape)\n",
    "\n",
    "feature_ids_char = input_data['feature_IDs_taskposneg_char']\n",
    "f_ids_char = pd.DataFrame(feature_ids_char)\n",
    "feature_ids_char = f_ids_char.to_numpy()\n",
    "print(\"feature_ids_char size\",feature_ids_char.shape)\n",
    "\n",
    "day1_data = input_data['sfc_taskposneg_ComBat_day1']\n",
    "d1 = pd.DataFrame(day1_data)\n",
    "day1_data = d1.to_numpy()\n",
    "print(\"day1_data size\",day1_data.shape)\n",
    "\n",
    "day2_data = input_data['sfc_taskposneg_ComBat_day2']\n",
    "d2 = pd.DataFrame(day2_data)\n",
    "day2_data = d2.to_numpy()\n",
    "print(\"day2_data size\",day2_data.shape)\n",
    "\n",
    "day3_data = input_data['sfc_taskposneg_ComBat_day3']\n",
    "d3 = pd.DataFrame(day3_data)\n",
    "day3_data = d3.to_numpy()\n",
    "print(\"day3_data size\",day3_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 size (36, 4503)\n",
      "data2 size (36, 4503)\n",
      "data3 size (36, 4503)\n"
     ]
    }
   ],
   "source": [
    "# the result above shows that N is 190 which is the number of features and 36 is the numer of subjects\n",
    "# the required datasets for training and testing need to be transposed to conform to nsamples x nfeatures scope\n",
    "#****************************************************************************************************************\n",
    "data1 = np.transpose(day1_data)\n",
    "print(\"data1 size\", data1.shape)\n",
    "\n",
    "data2 = np.transpose(day2_data)\n",
    "print(\"data2 size\", data2.shape)\n",
    "\n",
    "data3 = np.transpose(day3_data)\n",
    "print(\"data3 size\", data3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x12_train size (57, 4503)\n",
      "y12_train size (57,)\n",
      "x12_test size (15, 4503)\n",
      "y12_test size (15,)\n",
      "x13_train size (57, 4503)\n",
      "y13_train size (57,)\n",
      "x13_test size (15, 4503)\n",
      "y13_test size (15,)\n",
      "x23_train size (57, 4503)\n",
      "y23_train size (57,)\n",
      "x23_test size (15, 4503)\n",
      "y23_test size (15,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and testing sets for our model classifiers using test_train_split module in sklearn\n",
    "# we first combine the datasets in the following way\n",
    "# data12 = data1 + data2 | data13 = data1 + data3 | data23 = data2 + data3;\n",
    "#*********************************************************************************************************\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#generate training and testing datasets for classifier for day1 and day2 data\n",
    "# Y data has to be generated using numpy for y_train and y_test data as well\n",
    "data12 = np.concatenate((data1, data2), axis = 0)\n",
    "y1 = np.zeros(data1.shape[0])\n",
    "y2 = np.ones(data2.shape[0])\n",
    "y12 = np.concatenate((y1, y2), axis = 0)\n",
    "\n",
    "#generate training and testing datasets for classifier for day2 and day3 data\n",
    "# Y data has to be generated using numpy for y_train and y_test data as well\n",
    "data23 = np.concatenate((data2, data3), axis = 0)\n",
    "y2 = np.zeros(data2.shape[0])\n",
    "y3 = np.ones(data3.shape[0])\n",
    "y23 = np.concatenate((y2, y3), axis = 0)\n",
    "\n",
    "\n",
    "#generate training and testing datasets for classifier for day1 and day3 data\n",
    "# Y data has to be generated using numpy for y_train and y_test data as well\n",
    "data13 = np.concatenate((data1, data3), axis = 0)\n",
    "y1 = np.zeros(data1.shape[0])\n",
    "y3 = np.ones(data3.shape[0])\n",
    "y13 = np.concatenate((y1, y3), axis = 0)\n",
    "\n",
    "\n",
    "# split concatenated data into training and testing sets\n",
    "X12_train, X12_test, Y12_train, Y12_test = train_test_split(data12, y12, test_size = 0.2, random_state = 10)\n",
    "print('x12_train size', X12_train.shape)\n",
    "print('y12_train size', Y12_train.shape)\n",
    "print('x12_test size', X12_test.shape)\n",
    "print('y12_test size', Y12_test.shape)\n",
    "\n",
    "X13_train, X13_test, Y13_train, Y13_test = train_test_split(data13, y13, test_size = 0.2, random_state = 10)\n",
    "print('x13_train size', X13_train.shape)\n",
    "print('y13_train size', Y13_train.shape)\n",
    "print('x13_test size', X13_test.shape)\n",
    "print('y13_test size', Y13_test.shape)\n",
    "\n",
    "X23_train, X23_test, Y23_train, Y23_test = train_test_split(data23, y23, test_size = 0.2, random_state = 10)\n",
    "print('x23_train size', X23_train.shape)\n",
    "print('y23_train size', Y23_train.shape)\n",
    "print('x23_test size', X23_test.shape)\n",
    "print('y23_test size', Y23_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Build model classifiers for each predictions, and test its predictive accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model classifier to be built will be based on logistics regression with regularization capability.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# build classfier12\n",
    "classifier_12 = LogisticRegression(penalty='l2', dual=False, tol=0.00001, C=1.0, fit_intercept=True, \n",
    "                                  intercept_scaling=1, class_weight='balanced', solver='newton-cg', max_iter=1000,\n",
    "                                  multi_class='auto')\n",
    "\n",
    "#build classifier23\n",
    "classifier_13 = LogisticRegression(penalty='l2', dual=False, tol=0.00001, C=1.0, fit_intercept=True, \n",
    "                                  intercept_scaling=1, class_weight='balanced', solver='newton-cg', max_iter=1000,\n",
    "                                  multi_class='auto')\n",
    "\n",
    "classifier_23 = LogisticRegression(penalty='l2', dual=False, tol=0.00001, C=1.0, fit_intercept=True, \n",
    "                                  intercept_scaling=1, class_weight='balanced', solver='newton-cg', max_iter=1000,\n",
    "                                  multi_class='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, solver='newton-cg',\n",
       "                   tol=1e-05)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the classifier model built \n",
    "\n",
    "# classifier12 training\n",
    "classifier_12.fit(X12_train, Y12_train)\n",
    "\n",
    "# classifier13 training\n",
    "classifier_13.fit(X13_train, Y13_train)\n",
    "\n",
    "#classifier23 training\n",
    "classifier_23.fit(X23_train, Y23_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Test the prediction accuracy of our classifiers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction Accuracy of classifier12 on test set X12: 46.66667%\n",
      "prediction Accuracy of classifier13 on test set X13: 46.66667%\n",
      "prediction Accuracy of classifier23 on test set X23: 46.66667%\n"
     ]
    }
   ],
   "source": [
    "#Test the classifiers for prediction accuracy and number of positive and negative predictions\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#classifier12 accuracy on test set X12\n",
    "y12_pred = classifier_12.predict(X12_test)\n",
    "print('prediction Accuracy of classifier12 on test set X12: {:.5f}%'.format(classifier_12.score(X12_test, Y12_test)*100))\n",
    "\n",
    "#classifier13 accuracy on test set X13\n",
    "y13_pred = classifier_13.predict(X13_test)\n",
    "print('prediction Accuracy of classifier13 on test set X13: {:.5f}%'.format(classifier_13.score(X13_test, Y13_test)*100))\n",
    "\n",
    "#classifier23 accuracy on test set X23\n",
    "y23_pred = classifier_23.predict(X23_test)\n",
    "print('prediction Accuracy of classifier23 on test set X23: {:.5f}%'.format(classifier_23.score(X23_test, Y23_test)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction matrix for classifier12:  [[4 4]\n",
      " [4 3]]\n",
      "prediction matrix for classifier13:  [[3 5]\n",
      " [3 4]]\n",
      "prediction matrix for classifier23:  [[4 4]\n",
      " [4 3]]\n"
     ]
    }
   ],
   "source": [
    "# check the number of positive and negative predictions\n",
    "\n",
    "#classifier12 number of predictions\n",
    "matrix_12 = confusion_matrix(Y12_test, y12_pred)\n",
    "print('prediction matrix for classifier12: ', matrix_12)\n",
    "\n",
    "#classifier13 number of predictions\n",
    "matrix_13 = confusion_matrix(Y13_test, y13_pred)\n",
    "print('prediction matrix for classifier13: ', matrix_13)\n",
    "\n",
    "#classifier23 number of predictions\n",
    "matrix_23 = confusion_matrix(Y23_test, y23_pred)\n",
    "print('prediction matrix for classifier23: ', matrix_23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Cross-validation for the evaluation of our classifiers using 'leave-one-out' & 'k-fold' methods__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean accuracy is: 0.4305555555555556\n",
      "the standard deviation of the accuracy is: 0.49862879271703475\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation using Leave-One-Out method\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mean\n",
    "from statistics import stdev\n",
    "\n",
    "# carry out cross validation on classifier12 model\n",
    "data12 = np.concatenate((data1, data2), axis = 0)\n",
    "y1 = np.zeros(data1.shape[0])\n",
    "y2 = np.ones(data1.shape[0])\n",
    "y = np.concatenate((y1, y2), axis = 0)\n",
    "\n",
    "loo_12 = LeaveOneOut()\n",
    "loo_12_result=[]\n",
    "for train_index, test_index in loo_12.split(data12):\n",
    "    x12l_train, x12l_test = data12[train_index], data12[test_index]\n",
    "    y12l_train, y12l_test = y[train_index], y[test_index]\n",
    "    classifier_12.fit(x12l_train, y12l_train)\n",
    "    y12l_pred = classifier_12.predict(x12l_test)\n",
    "    loo_12_result.append(accuracy_score(y12l_test, y12l_pred))\n",
    "\n",
    "# accumulated loo result    \n",
    "acc_result_12 = loo_12_result\n",
    "\n",
    "#calculate the standard deviation and mean of the accuracy\n",
    "print(\"the mean accuracy is: {}\".format(mean(acc_result_12)))\n",
    "print(\"the standard deviation of the accuracy is: {}\".format(stdev(acc_result_12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean accuracy is: 0.5555555555555556\n",
      "the standard deviation of the accuracy is: 0.5003910833605344\n"
     ]
    }
   ],
   "source": [
    "# carry out cross validation on classifier13 model\n",
    "data13 = np.concatenate((data1, data3), axis = 0)\n",
    "y1 = np.zeros(data1.shape[0])\n",
    "y3 = np.ones(data1.shape[0])\n",
    "y = np.concatenate((y1, y3), axis = 0)\n",
    "\n",
    "loo_13 = LeaveOneOut()\n",
    "loo_13_result=[]\n",
    "for train_index, test_index in loo_13.split(data13):\n",
    "    x13l_train, x13l_test = data13[train_index], data13[test_index]\n",
    "    y13l_train, y13l_test = y[train_index], y[test_index]\n",
    "    classifier_13.fit(x13l_train, y13l_train)\n",
    "    y13l_pred = classifier_13.predict(x13l_test)\n",
    "    loo_13_result.append(accuracy_score(y13l_test, y13l_pred))\n",
    "\n",
    "# accumulated loo result    \n",
    "acc_result_13 = loo_13_result\n",
    "\n",
    "#calculate the standard deviation and mean of the accuracy\n",
    "print(\"the mean accuracy is: {}\".format(mean(acc_result_13)))\n",
    "print(\"the standard deviation of the accuracy is: {}\".format(stdev(acc_result_13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean accuracy is: 0.6666666666666666\n",
      "the standard deviation of the accuracy is: 0.47471266327754136\n"
     ]
    }
   ],
   "source": [
    "# carry out cross validation on classifier13 model\n",
    "data23 = np.concatenate((data2, data3), axis = 0)\n",
    "y2 = np.zeros(data1.shape[0])\n",
    "y3 = np.ones(data1.shape[0])\n",
    "y = np.concatenate((y2, y3), axis = 0)\n",
    "\n",
    "loo_23 = LeaveOneOut()\n",
    "loo_23_result=[]\n",
    "for train_index, test_index in loo_23.split(data23):\n",
    "    x23l_train, x23l_test = data23[train_index], data23[test_index]\n",
    "    y23l_train, y23l_test = y[train_index], y[test_index]\n",
    "    classifier_23.fit(x13l_train, y23l_train)\n",
    "    y23l_pred = classifier_23.predict(x23l_test)\n",
    "    loo_23_result.append(accuracy_score(y23l_test, y23l_pred))\n",
    "\n",
    "# accumulated loo result    \n",
    "acc_result_23 = loo_23_result\n",
    "\n",
    "#calculate the standard deviation and mean of the accuracy\n",
    "print(\"the mean accuracy is: {}\".format(mean(acc_result_23)))\n",
    "print(\"the standard deviation of the accuracy is: {}\".format(stdev(acc_result_23)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean accuracy is: 0.4166666666666667\n",
      "the standard deviation of the accuracy is: 0.13975424859373686\n"
     ]
    }
   ],
   "source": [
    "# cross validation for the evaluation of classifiers using k-fold method\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#kfold is implemented for n_split = 9\n",
    "\n",
    "# classifier12 model validation \n",
    "kf_12 = KFold(n_splits=9, shuffle=True, random_state=32)\n",
    "\n",
    "data12 = np.concatenate((data1, data2), axis = 0)\n",
    "y1 = np.zeros(data1.shape[0])\n",
    "y2 = np.ones(data1.shape[0])\n",
    "y = np.concatenate((y1, y2), axis = 0)\n",
    "\n",
    "kf_12_result = []\n",
    "for train_index, test_index in kf_12.split(data12):\n",
    "    x12k_train, x12k_test = data12[train_index], data12[test_index]\n",
    "    y12k_train, y12k_test = y[train_index], y[test_index]\n",
    "    classifier_12.fit(x12k_train, y12k_train)\n",
    "    y12k_pred = classifier_12.predict(x12k_test)\n",
    "    kf_12_result.append(accuracy_score(y12k_test, y12k_pred))\n",
    "\n",
    "# accumulated kfold result    \n",
    "acc_result_12 = kf_12_result\n",
    "\n",
    "#calculate the standard deviation and mean of the accuracy\n",
    "print(\"the mean accuracy is: {}\".format(mean(acc_result_12)))\n",
    "print(\"the standard deviation of the accuracy is: {}\".format(stdev(acc_result_12)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean accuracy is: 0.5\n",
      "the standard deviation of the accuracy is: 0.1875\n"
     ]
    }
   ],
   "source": [
    "# cross-validation for classifier13\n",
    "kf_13 = KFold(n_splits=9, shuffle=True, random_state=32)\n",
    "\n",
    "data13 = np.concatenate((data1, data3), axis = 0)\n",
    "y1 = np.zeros(data1.shape[0])\n",
    "y3 = np.ones(data1.shape[0])\n",
    "y = np.concatenate((y1, y3), axis = 0)\n",
    "\n",
    "kf_13_result = []\n",
    "for train_index, test_index in kf_13.split(data13):\n",
    "    x13k_train, x13k_test = data13[train_index], data13[test_index]\n",
    "    y13k_train, y13k_test = y[train_index], y[test_index]\n",
    "    classifier_13.fit(x13k_train, y13k_train)\n",
    "    y13k_pred = classifier_13.predict(x13k_test)\n",
    "    kf_13_result.append(accuracy_score(y13k_test, y13k_pred))\n",
    "\n",
    "# accumulated kfold result    \n",
    "acc_result_13 = kf_13_result\n",
    "\n",
    "#calculate the standard deviation and mean of the accuracy\n",
    "print(\"the mean accuracy is: {}\".format(mean(acc_result_13)))\n",
    "print(\"the standard deviation of the accuracy is: {}\".format(stdev(acc_result_13)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean accuracy is: 0.5\n",
      "the standard deviation of the accuracy is: 0.22534695471649932\n"
     ]
    }
   ],
   "source": [
    "# cross-validation for classifier23\n",
    "kf_23 = KFold(n_splits=9, shuffle=True, random_state=32)\n",
    "\n",
    "data23 = np.concatenate((data2, data3), axis = 0)\n",
    "y2 = np.zeros(data1.shape[0])\n",
    "y3 = np.ones(data1.shape[0])\n",
    "y = np.concatenate((y2, y3), axis = 0)\n",
    "\n",
    "kf_23_result = []\n",
    "for train_index, test_index in kf_23.split(data23):\n",
    "    x23k_train, x23k_test = data23[train_index], data23[test_index]\n",
    "    y23k_train, y23k_test = y[train_index], y[test_index]\n",
    "    classifier_23.fit(x23k_train, y23k_train)\n",
    "    y23k_pred = classifier_23.predict(x23k_test)\n",
    "    kf_23_result.append(accuracy_score(y23k_test, y23k_pred))\n",
    "\n",
    "# accumulated kfold result    \n",
    "acc_result_23 = kf_23_result\n",
    "\n",
    "#calculate the standard deviation and mean of the accuracy\n",
    "print(\"the mean accuracy is: {}\".format(mean(acc_result_23)))\n",
    "print(\"the standard deviation of the accuracy is: {}\".format(stdev(acc_result_23)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Feature Importance using both 'recursive feature elimination' and 'permutation testing'__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance using recuresive feature elimination as feature selector\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#the RFE wrapper method for estimating the features that contribute relatively to the classifier's prediction of a target\n",
    "def recur_feat_elim(d1, d2):\n",
    "    d1d2 = np.concatenate((d1, d2), axis = 0)\n",
    "    y1y2 = np.concatenate((np.ones(data1.shape[0]) , np.zeros(data1.shape[0])), axis = 0)\n",
    "    \n",
    "    # to accurately estimate the feature importance we adopt one of the cross validation methods \n",
    "    #to prepare our model for prediction. RFE method selects the 15 best features.\n",
    "    kf_cv = KFold(n_splits=9, shuffle=True, random_state=32)\n",
    "    rfe_ranking = dict()\n",
    "    classifier = LogisticRegression(penalty='l2', dual=False, tol=0.00001, C=1.0, fit_intercept=True, \n",
    "                                  intercept_scaling=1, class_weight='balanced', solver='newton-cg', max_iter=1000,\n",
    "                                  multi_class='auto')\n",
    "    for train_idx, test_idx in kf_cv.split(d1d2):\n",
    "        rfe_model = RFE(classifier, n_features_to_select=15 )\n",
    "        x_rfe_train, x_rfe_test = d1d2[train_idx], d1d2[test_idx]\n",
    "        y_rfe_train, y_rfe_test = y1y2[train_idx], y1y2[test_idx]\n",
    "        f_selector = rfe_model.fit(x_rfe_train, y_rfe_train)\n",
    "        \n",
    "        #we give ranking of 1 to the best 15 features selected \n",
    "        f_import_idx = np.where(f_selector.ranking_ == 1)[0]\n",
    "        features_importance = feature_ids[f_import_idx]\n",
    "        \n",
    "        # for the input features in the dataset considered we determine how frequent the best features appear \n",
    "        for feat in range(features_importance.shape[0]):\n",
    "            rfe_ranking[str(features_importance[feat])] = rfe_ranking.get(str(features_importance[feat]), 0) + 1\n",
    "            \n",
    "    return rfe_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ranking in day1&2 datasets:  ['[49 42]', '[49 50]', '[11 16]', '[11 22]', '[24 38]', '[18 42]', '[ 1 48]', '[46  4]', '[11 33]', '[53 42]', '[37 46]', '[56 46]', '[55 24]', '[40 51]']\n",
      "features ranking in day1&3 datasets:  ['[49 33]', '[45 46]', '[ 1 11]', '[24 12]', '[ 3 22]', '[34 37]', '[26 47]', '[31  3]', '[ 5 24]', '[24 40]', '[19 43]', '[ 8 33]', '[23 52]', '[45  8]', '[21 20]', '[21 18]', '[45 52]', '[8 5]', '[46 42]', '[46  7]', '[46 36]', '[23 57]', '[51 41]', '[22  3]', '[ 6 22]', '[31 15]', '[11 38]', '[ 5 44]', '[36  9]', '[13 18]', '[35 18]', '[40 23]', '[23 30]', '[ 9 37]', '[47 42]', '[53 47]', '[11 21]', '[14 22]', '[11 35]', '[30  7]', '[60 10]', '[41 42]', '[13 28]', '[12 29]', '[11 43]', '[ 6 55]', '[26  4]', '[44 27]', '[ 3 41]', '[23 46]', '[11 55]', '[ 3 56]', '[23 17]', '[61 41]', '[49 42]', '[19 45]', '[ 5 19]', '[11 34]', '[53  9]', '[21 16]', '[10 24]', '[16 25]', '[15 35]', '[48 50]', '[7 1]', '[10 32]', '[34 48]', '[17 54]', '[12 10]', '[13 22]', '[ 4 55]', '[24 20]', '[49 45]', '[13 46]', '[25 51]', '[ 6 17]', '[ 9 41]', '[ 9 46]', '[28 50]', '[ 1 44]', '[ 8 52]', '[49 15]', '[15 22]', '[28 22]', '[15 31]', '[29 32]', '[25 39]']\n",
      "features ranking in day2&3 datasets:  ['[ 1 48]', '[49 57]', '[29 17]', '[ 5 43]', '[12 38]', '[13 18]', '[16 36]', '[ 1 52]', '[ 2 15]', '[45 19]', '[56 54]', '[33 54]', '[31 34]', '[56 55]', '[15  3]', '[64 14]', '[60 42]', '[40 46]', '[60 55]', '[13 37]', '[ 8 37]', '[ 2 20]', '[59 42]', '[2 7]', '[42 37]', '[ 2 19]', '[51 12]', '[7 5]']\n"
     ]
    }
   ],
   "source": [
    "#find the 15 best features that have the highest frequency of appreance in the datasets considered\n",
    "def feat_import(d1, d2):\n",
    "    \n",
    "    rfe_rank = recur_feat_elim(d1, d2)\n",
    "    \n",
    "    temp = rfe_rank.copy()\n",
    "    test_val = -99999999\n",
    "    rank = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        max_num = test_val\n",
    "        for val in temp.keys():\n",
    "            if(temp[val] > max_num):\n",
    "                max_num = temp[val]\n",
    "        for key, value in rfe_rank.items():\n",
    "            if(value == max_num):\n",
    "                rank.append(key)\n",
    "                temp[key] = 0\n",
    "    return rank\n",
    "\n",
    "\n",
    "#Run the RFE feature selector method on the 3 classifiers\n",
    "\n",
    "\n",
    "rank12 = feat_import(data1, data2)\n",
    "print('features ranking in day1&2 datasets: ', rank12)\n",
    "\n",
    "rank13 = feat_import(data1, data3)\n",
    "print('features ranking in day1&3 datasets: ', rank13)\n",
    "\n",
    "rank23 = feat_import(data2, data3)\n",
    "print('features ranking in day2&3 datasets: ', rank23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features performance  with Permutation Testing method \n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def perm_import(d1, d2):\n",
    "    d1d2 = np.concatenate((d1, d2), axis = 0)\n",
    "    y1y2 = np.concatenate((np.ones(data1.shape[0]) , np.zeros(data1.shape[0])), axis = 0)\n",
    "    \n",
    "    # to accurately estimate the feature importance we adopt one of the cross validation methods \n",
    "    #to prepare our model for prediction. premutation importance method to determine the relatinoship between a feature an a target.\n",
    "    kf_cv = KFold(n_splits=9, shuffle=True, random_state=32)\n",
    "    PI_ranking = dict()\n",
    "    classifier = LogisticRegression(penalty='l2', dual=False, tol=0.00001, C=1.0, fit_intercept=True, \n",
    "                                  intercept_scaling=1, class_weight='balanced', solver='newton-cg', max_iter=1000,\n",
    "                                  multi_class='auto')\n",
    "    for train_idx, test_idx in kf_cv.split(d1d2):\n",
    "        x_pi_train, x_pi_test = d1d2[train_idx], d1d2[test_idx]\n",
    "        y_pi_train, y_pi_test = y1y2[train_idx], y1y2[test_idx]\n",
    "        model = classifier.fit(x_pi_train, y_pi_train)\n",
    "        pi = permutation_importance(model, x_pi_test, y_pi_test, n_repeats=30)\n",
    "        \n",
    "        # permutation importance technique breaks the relationship between feature and target which reduces the model's accuracy.  \n",
    "        for r in pi.importances_mean.argsort()[::-1]:\n",
    "            if(pi.importances_mean[r] * 2 - r.importances_std[r] > 0):\n",
    "                PI_ranking[str(feature_ids[r])] = PI_ranking.get(str(feature_ids[r]), 0) + 1\n",
    "            \n",
    "    return PI_ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ranking in day1&2 datasets:  ['[49 42]', '[49 50]', '[11 16]', '[11 22]', '[24 38]', '[18 42]', '[ 1 48]', '[46  4]', '[11 33]', '[53 42]', '[37 46]', '[56 46]', '[55 24]', '[40 51]']\n",
      "features ranking in day1&3 datasets:  ['[49 33]', '[45 46]', '[ 1 11]', '[24 12]', '[ 3 22]', '[34 37]', '[26 47]', '[31  3]', '[ 5 24]', '[24 40]', '[19 43]', '[ 8 33]', '[23 52]', '[45  8]', '[21 20]', '[21 18]', '[45 52]', '[8 5]', '[46 42]', '[46  7]', '[46 36]', '[23 57]', '[51 41]', '[22  3]', '[ 6 22]', '[31 15]', '[11 38]', '[ 5 44]', '[36  9]', '[13 18]', '[35 18]', '[40 23]', '[23 30]', '[ 9 37]', '[47 42]', '[53 47]', '[11 21]', '[14 22]', '[11 35]', '[30  7]', '[60 10]', '[41 42]', '[13 28]', '[12 29]', '[11 43]', '[ 6 55]', '[26  4]', '[44 27]', '[ 3 41]', '[23 46]', '[11 55]', '[ 3 56]', '[23 17]', '[61 41]', '[49 42]', '[19 45]', '[ 5 19]', '[11 34]', '[53  9]', '[21 16]', '[10 24]', '[16 25]', '[15 35]', '[48 50]', '[7 1]', '[10 32]', '[34 48]', '[17 54]', '[12 10]', '[13 22]', '[ 4 55]', '[24 20]', '[49 45]', '[13 46]', '[25 51]', '[ 6 17]', '[ 9 41]', '[ 9 46]', '[28 50]', '[ 1 44]', '[ 8 52]', '[49 15]', '[15 22]', '[28 22]', '[15 31]', '[29 32]', '[25 39]']\n",
      "features ranking in day2&3 datasets:  ['[ 1 48]', '[49 57]', '[29 17]', '[ 5 43]', '[12 38]', '[13 18]', '[16 36]', '[ 1 52]', '[ 2 15]', '[45 19]', '[56 54]', '[33 54]', '[31 34]', '[56 55]', '[15  3]', '[64 14]', '[60 42]', '[40 46]', '[60 55]', '[13 37]', '[ 8 37]', '[ 2 20]', '[59 42]', '[2 7]', '[42 37]', '[ 2 19]', '[51 12]', '[7 5]']\n"
     ]
    }
   ],
   "source": [
    "# We want to see the level of improtance each feature that was severed from a target is.\n",
    "\n",
    "def feat_import_PI(d1, d2):\n",
    "    \n",
    "    PI_rank = perm_import(d1, d2)\n",
    "    \n",
    "    temp = PI_rank.copy()\n",
    "    test_val = -99999999\n",
    "    rank = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        max_num = test_val\n",
    "        for val in temp.keys():\n",
    "            if(temp[val] > max_num):\n",
    "                max_num = temp[val]\n",
    "        for key, value in PI_rank.items():\n",
    "            if(value == max_num):\n",
    "                rank.append(key)\n",
    "                temp[key] = 0\n",
    "    return rank\n",
    "\n",
    "\n",
    "#Run the Permutation importance method on the 3 classifiers\n",
    "\n",
    "rank12 = feat_import(data1, data2)\n",
    "print('features ranking in day1&2 datasets: ', rank12)\n",
    "\n",
    "rank13 = feat_import(data1, data3)\n",
    "print('features ranking in day1&3 datasets: ', rank13)\n",
    "\n",
    "rank23 = feat_import(data2, data3)\n",
    "print('features ranking in day2&3 datasets: ', rank23)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
